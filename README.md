# Course: Computer Vision, SP 21, Indiana University, Bloomington

## Assignment 1: OMR
## Submission by: A. Ahuja, S. Tyagi, R. Mariyappan, K. Pimparkar, N. Faro [Group 3]


## Introduction
This assignment targets to implement Optical Image Recofnition (OCR) to detect symbols of musical notes, quarter rests and eighth rests in the provided images. The output of this process is the input images with annotations to indicate the pitch of the detected symbol with a bounding box. It also outputs a text indicating following details of the detected symbol:
row position,column position, height of the bounding box, width of the bounding box, type of thedetected symbol, pitch of the symbol and confidence score of the detection.

The musical notes, quareter rests and eighth rests are taken as inputs in the form of templates. The OCR process then executes following steps to achieve template matching:

## Detection of the staves
Each image has musical notes arranged on staves which appear in groups of 5. We need coordinates of these staves and spacing in between these staves in order to determine relative positions of provided musical symbols. These staves are 5 parallel lines located horizontally on the input image. The spacing between these staves also indicate the scale of the image which is needed to rescale templates before we perform template matching.
Therefore, we used following methods to detect these staves:

### Canny edge detection 
We went in with the hypothesis that the lines detected from an edge detection algorithm would have high mean intensity values across the rows as compared to the other places in the image. 

To validate our hypothesis, we first performed hough transform on the image space. The output is given below for the first image. It worked very well for the first 2 images but for multiple lines, the algorithm broke as it was giving many false positive lines due to the high pixel intensity values at places in the image where there was a lot of noise. 

Then, we moved to another approach and tried the Canny edge detector on the image. Canny edge detector proved to be a very robust method for line detection. Canny edge detector whitens the lines and puts black pixels elsewhere. 

This worked perfectly with our hypothesis and we were able to detect coordinates of all lines in the image by basically getting the mean pixel values along the row in the image. The mean pixel values for the lines proved to be very high as compared to the other places in the image. By choosing a suitable threshold, we were able to get the coordinates of the lines. Using that we were also able to get the spacing parameter between the lines which was also used to rescale the template later. This whole process is performed in the function get_coordinates_spacing()

Sample output of this methos is as follows:
```
  2.0 sets of stave lines with mode spacing parameter:12
  Staves' indexes:  [29, 41, 52, 64, 75, 150, 162, 173, 185, 196]
```

### Hough transform
We used a threshold value of 180 pizel  intesity to identify staves in the image. All pixels having intensity less than this value are considered as black pixels, leaving horizontal staves with brighter pixels. We generate a parameter space for the input image using the Hough transform. 

Following the format y = m*x + b where y is y-coord, x is x-coord, m is slope and b is bias. x and y are in image space, while m and b are in hough space. To detect groups of  five lines, we subsitute b with row coordinate of the first stave line and m by the spacing between the lines.
The output of this process is as follows:

![Hough_transform_Music1](/outputs/Hough_transform_Music1.png)

This approach worked on simple input images where we had just two pairs of 5 staves. This approach started to fail for complex images due to the noise generated by excessive number of intersecting lines in parameter space.

This led us to move to Canny edge detection method described above.

### Using 2D Conv
In order to detect staves we found out that generating edge map of the input image is a better idea. Therefore we used Sobel operator with 2D convolution to get edge maps of input images. Even though we were successful in generating edge maps in this fashion, the application of scoring function produced less accurate outcomes as compared to Canny edge maps. 

We noticed that the reason for these less accurate results was two folds, first the sobel edge detection generated multiple edges resulting in blurred edge map. Additionally, sobel edge map allowed usage of single threshold on pixel intensities which generated less accurate edges. Canny edge map helped to get rid of limitations hence we moved on to using Canny edge maps instead of Sobel edge maps.

## Template rescaling  
In real world scenarios, the template and the main image won't be on same scale. Hence, we needed to introduce a step to rescale either the image ot templates so that both are on same scale. We chose to rescale templates dynamically by calculating the scale of the image.   

We calculated the spacing between staves in previous step, using this information we calculated the new scale of the templates as below:
- New height of template 1 = spacing value  * 1  
- New height of template 2 = spacing value  * 3  
- New height of template 3 = spacing value  * 2.5  

In order to keep the aspect ratio same, the new width of the templates is calculated using the original ration between the width and height as below:  
 ```bash
 w' = h' * (w/h)
 ```
 
## Hamming distance calculation  
The template matching step needs computation of a scoring function. We used Hamming distance as the scoring function to determine the similarity between the image and the template. In this method we calculated the number of pixels where the pixel intensities of template don't match with a patch taken from the original image. This process is iterated over the whole image to find value of Hamming distance at each pixel. 

The output of this step provided us an array which is usedin the templating matching process.

## Performing template matching  
In this step we decided cutoff values for the combination of image and template. These threshold pixel intensities are used to highlight only those pixels where the template matches with the image. 
After performing multiple iterations of this step, we came up with following cutoff values of the pixel intensities:

|Image|Template1|Template2|Template3|
|-----|---------|---------|---------|
|Music1|220|250|245|
|Music2|230|254|230|
|Music3|220|253|252|
|Default|220|253|220|
    
## Non Maximum Supression to avoid multiple detections
The Hamming distance method explained above resulted in multiple detection of same musical symbol. Therefore, we implemented Non Maximum Supression to eliminate less accurate detections. 

In order to achive this, we first calculated the positions of each bounding box which is expected to hold the matched template. Then, we calculated area of each such bounding box. At this point, we were able to calculate the area of the most compact box which would contain the template. We compared the area of such box with the area of each bounding box and discarded all boxes where we noticed high overlap between the area, avoiding multiple detections.
This process available in the function `non_max_suppression`

## Annotating the musical symbols
The pitch or annotations are detected based on the position of the matched template relative the positions of the detected staves. In order to achive this the y-coordinate of each identified bounding box is compared with the coordinates of staves. Based on the relative values of these two locations, we assigned the pitch to each detected symbols. 

### Annotated images
* OMR output for music1.png
![music1_output.png](/outputs/music1_output.png)

* OMR output for music2.png
![music2_output.png](/outputs/music2_output.png)

* OMR output for music3.png
![music1_output.png](/outputs/music3_output.png)

* OMR output for music4.png
![music2_output.png](/outputs/music4_output.png)


### Accuracy results
We received fairely accurate results as shown in following table:

|Image|correct|misclassified|unclassified|Accuracy|
|-----|-------|-------------|------------|--------|
|Image1|44|1|1|0.9565|
|Image2|19|5|17|0.4634|
|Image3|73|54|75|0.3613|
|Image4|64|32|5|0.6336|

* Color coded input imaged to indicate accuracy of detection:
**Color code **  
Green = Correct classification  
Red/Orance = Misclassified  
Pink = Unclassified  
Teal = Bogus detection  

- Accuracy marking for music1.png
![1.png](/marked-images/1.png)
- Accuracy marking for music2.png
![2.png](/marked-images/2.png)
- Accuracy marking for music3.png
![3.png](/marked-images/3.png)
- Accuracy marking for music4.png
![4.png](/marked-images/4.png)

## Conclusion
This assignment allowed us to work on implementing various algorithms such as Hamming distance, convolution, Hough transform, Non Maximum Suppression. Implemenmtion of these algorithms using basic python function deepened our understanding of these algorithms.   
There is scope for further work on this task by using different scoring functions. Additionally, the code can be further fine tuned for improved performance and accuracy. 
